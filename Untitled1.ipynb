{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bc672a",
   "metadata": {},
   "source": [
    "# importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19a406e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition\n",
    "import simpleaudio\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import winsound\n",
    "import smtplib\n",
    "import imghdr \n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "import ssl\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.text import MIMEText\n",
    "from email import encoders\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc6ba9",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17baeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envoyer_email(i,s):\n",
    "\n",
    "    removed_directory = i.replace('Desktop/amerbot/unknown/',': ')\n",
    "    time_formatted =  removed_directory.replace(',',':')\n",
    "    chemin=time_formatted.replace('.png','')\n",
    "    \n",
    "    sender = 'ameur.ameur.35791@gmail.com'\n",
    "    password = #password and permission required are only configured on the local machine or get yours on app passwords from google\n",
    "    rec = 'selmi.amer.10@gmail.com'\n",
    "    subject = s+'!'\n",
    "    body = 'at '+chemin\n",
    "    \n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = subject \n",
    "    msg['From'] = sender\n",
    "    msg['To'] = rec\n",
    "    msg.attach(MIMEText(body))\n",
    "\n",
    "    s='Desktop/amerbot/Audio/'+s+'.wav'\n",
    "    sss=open(s,'rb')\n",
    "    part = MIMEBase('application', \"octet-stream\")\n",
    "    part.set_payload(sss.read())\n",
    "    encoders.encode_base64(part)\n",
    "    part.add_header('Content-Disposition','attachment; filename= '+'Audio.wav')\n",
    "    msg.attach(part)\n",
    "    \n",
    "\n",
    "    sss=open(i,'rb')\n",
    "    part = MIMEBase('application', \"octet-stream\")\n",
    "    part.set_payload(sss.read())\n",
    "    encoders.encode_base64(part)\n",
    "\n",
    "    part.add_header('Content-Disposition','attachment; filename= '+'fire.png')\n",
    "    msg.attach(part)\n",
    "\n",
    "    context = ssl.create_default_context()\n",
    "    \n",
    "\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com',465,context=context) as smtp:\n",
    "        smtp.login(sender,password)\n",
    "        smtp.sendmail(sender,rec,msg.as_string())\n",
    "        print('....Email D\\'alerte envoyÃ© ....' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccca3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_rec(valid):\n",
    "    recognizer = speech_recognition.Recognizer()\n",
    "    password='bonjour'\n",
    "    text=''\n",
    "    c=0\n",
    "    valid=False\n",
    "    while True:\n",
    "        if c==3:           \n",
    "            break\n",
    "        with speech_recognition.Microphone() as mic:        \n",
    "            wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/donner le mot de passe svp.wav\")\n",
    "            play_obj = wave_obj.play()\n",
    "            play_obj.wait_done()            \n",
    "            recognizer.adjust_for_ambient_noise(mic, duration=0.2)            \n",
    "            try:\n",
    "                audio = recognizer.listen(mic)\n",
    "                text = recognizer.recognize_google(audio)  \n",
    "                print(text)\n",
    "                text=text.lower()\n",
    "            except:\n",
    "                c=c+1\n",
    "                print('exception')\n",
    "                continue\n",
    "                \n",
    "            print('xt: '+text)\n",
    "            if password in text:               \n",
    "                wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/Bienvenue.wav\")\n",
    "                play_obj = wave_obj.play()\n",
    "                play_obj.wait_done()\n",
    "                valid=True\n",
    "                break\n",
    "            else:          \n",
    "                wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/mot de passe incorrecte.wav\")\n",
    "                play_obj = wave_obj.play()\n",
    "                play_obj.wait_done()\n",
    "                valid=False\n",
    "                break\n",
    "    return valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c2e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alarm():\n",
    "    wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/alarm.wav\")\n",
    "    play_obj = wave_obj.play()\n",
    "    play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a49fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEncodeings(image):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27c81bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amer', 'elon', 'linda']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = 'Desktop/amerbot/persons'\n",
    "images = []\n",
    "\n",
    "classNames = []\n",
    "personsList = os.listdir(path)\n",
    "\n",
    "for cl in personsList:\n",
    "    curPersonn = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curPersonn)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "\n",
    "\n",
    "encodeListKnown = findEncodeings(images)\n",
    "print(classNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9e897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02665af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wearing_mask(img):\n",
    "    \n",
    "    model=load_model(\"Desktop/amerbot/mask_nomask.h5\")\n",
    "    img = np.asarray(img)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    img = preProcessing(img)\n",
    "    img = img.reshape(1,32,32,1)\n",
    "   \n",
    "    predictions = model.predict(img)\n",
    "    classIndex = predictions.argmax(axis=1)\n",
    "    probVal= np.amax(predictions)\n",
    "   \n",
    "    if probVal> threshold:\n",
    "        if classIndex==0:\n",
    "            wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/mask.wav\")\n",
    "            play_obj = wave_obj.play()\n",
    "            play_obj.wait_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401836af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wearing_sunglasses(img):\n",
    "    \n",
    "    model=load_model(\"Desktop/amerbot/glasses.h5\")\n",
    "    img = np.asarray(img)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    img = preProcessing(img)\n",
    "    img = img.reshape(1,32,32,1)\n",
    "   \n",
    "    predictions = model.predict(img)\n",
    "    classIndex = predictions.argmax(axis=1)\n",
    "    probVal= np.amax(predictions)\n",
    "   \n",
    "    if probVal> threshold:\n",
    "        if classIndex==0:\n",
    "            wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/lunettes.wav\")\n",
    "            play_obj = wave_obj.play()\n",
    "            play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inconnue(img):\n",
    " \n",
    "    now = datetime.now()\n",
    "    temps = now.strftime(\"%d %B %H,%M\")\n",
    "    nom_image=temps + '.jpg'\n",
    "    chemin=\"Desktop/amerbot/unknown/\"\n",
    "    chemin=os.path.join(chemin+nom_image)\n",
    "    cv2.imwrite(chemin,img)\n",
    "    print(chemin)\n",
    "    wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/INC.wav\")\n",
    "    play_obj = wave_obj.play()\n",
    "    play_obj.wait_done()\n",
    "    \n",
    "    alarm()\n",
    "    \n",
    "    envoyer_email(chemin,'Unknown Person Detected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c412b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol(img):\n",
    "    \n",
    "    model=load_model(\"Desktop/amerbot/etc.h5\")\n",
    " \n",
    "    img = np.asarray(img)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    img = preProcessing(img)\n",
    "    img = img.reshape(1,32,32,1)\n",
    "   \n",
    "    predictions = model.predict(img)\n",
    "    classIndex = predictions.argmax(axis=1)\n",
    "    probVal= np.amax(predictions)\n",
    "   \n",
    "    if probVal> threshold:\n",
    "        if classIndex==0:\n",
    "            if x==2:\n",
    "                now = datetime.now()\n",
    "                temps = now.strftime(\"%d %B %H,%M\")\n",
    "                nom_image='temps' + '.jpg'\n",
    "                chemin=\"Desktop/amerbot/unknown/\"\n",
    "                chemin=os.path.join(chemin+nom_image)\n",
    "\n",
    "                cv2.imwrite(chemin,img)\n",
    "                print(chemin)\n",
    "                alarm()\n",
    "                envoyer_email(chemin,'quelqu\\'un a volÃ© un objet')\n",
    "            else:\n",
    "                x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dae248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire(img,y):\n",
    "\n",
    "    model=load_model(\"Desktop/amerbot/fire_mobile1.h5\")\n",
    "\n",
    "    img = np.asarray(img)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    img = preProcessing(img)\n",
    "    img = img.reshape(1,32,32,1)\n",
    "   \n",
    "    predictions = model.predict(img)\n",
    "    classIndex = predictions.argmax(axis=1)\n",
    "    probVal= np.amax(predictions)\n",
    "   \n",
    "    if probVal> threshold:\n",
    "        if classIndex==0:\n",
    "            if y==2:\n",
    "                now = datetime.now()\n",
    "                temps = now.strftime(\"%d %B %H,%M\")\n",
    "                nom_image='temps' + '.jpg'\n",
    "                chemin=\"Desktop/amerbot/unknown/\"\n",
    "                chemin=os.path.join(chemin+nom_image)\n",
    "                cv2.imwrite(chemin,img)\n",
    "                alarm()\n",
    "                envoyer_email(chemin,'fire')\n",
    "            else:\n",
    "                y+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07da6d",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Desktop/amerbot/unknown/05 June 17,55.jpg\n",
      "....10%\n",
      "....25%\n",
      "....50%\n",
      "....75%\n",
      "....90%\n",
      "....100%\n",
      "....Email D'alerte envoyÃ© ....\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "bonjour\n",
      "xt: bonjour\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "known=False\n",
    "valid=False\n",
    "threshold = 0.65\n",
    "x=0\n",
    "y=0\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0,0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    faceCurentFrame = face_recognition.face_locations(imgS)\n",
    "    \n",
    "    #checks if a person is standing against the camera or not\n",
    "    if len(faceCurentFrame)==0:\n",
    "        #check for fire\n",
    "        fire(img,x)\n",
    "        #check for stolen\n",
    "        vol(img)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        wave_obj = simpleaudio.WaveObject.from_wave_file(\"Desktop/amerbot/Audio/Bienvenue a etc.wav\")\n",
    "        play_obj = wave_obj.play()\n",
    "        play_obj.wait_done()\n",
    "        \n",
    "        if wearing_mask(img):\n",
    "            time.sleep(3)\n",
    "        elif wearing_sunglasses(img):\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "        \n",
    "            encodeCurentFrame = face_recognition.face_encodings(imgS, faceCurentFrame)\n",
    "            for encodeface, faceLoc in zip(encodeCurentFrame, faceCurentFrame):\n",
    "                matches = face_recognition.compare_faces(encodeListKnown, encodeface)\n",
    "                faceDis = face_recognition.face_distance(encodeListKnown, encodeface)\n",
    "                matchIndex = np.argmin(faceDis)\n",
    "\n",
    "                y1, x2, y2, x1 = faceLoc\n",
    "                y1, x2, y2, x1 = y1*4, x2*4, y2*4, x1*4\n",
    "\n",
    "                #testing the existance of the person in the dataset\n",
    "                if matches[matchIndex]:\n",
    "                    #name = classNames[matchIndex].upper()\n",
    "                    #cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "                    #cv2.rectangle(img, (x1,y2+35), (x2,y2), (0,255,0), cv2.FILLED)\n",
    "                    #cv2.putText(img, name, (x1+6, y2+25), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 1) \n",
    "                    if speech_rec(valid):\n",
    "                        #door opens\n",
    "                        time.sleep(4)\n",
    "                    else:\n",
    "                        inconnue(img)\n",
    "                        #door remains closed\n",
    "                    break\n",
    "                else:\n",
    "                    inconnue(img)\n",
    "                    break\n",
    "        \n",
    "    cv2.imshow('Face Recogntion', img)\n",
    "    key = cv2.waitKey(27)\n",
    "    if key == 27: \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d037df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb35e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b7a8c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db99f000",
   "metadata": {},
   "source": [
    "# Another way for Detecting sunglasses (using Eye brow Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16cfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# Load the pre-trained facial landmark detector from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"Desktop/amerbot/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read the video frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        # Detect facial landmarks\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Get the positions of the eyes and eyebrows\n",
    "        left_eye = landmarks.part(36).y\n",
    "        right_eye = landmarks.part(45).y\n",
    "        left_eyebrow = landmarks.part(19).y\n",
    "        right_eyebrow = landmarks.part(24).y\n",
    "        for i in range(17, 22):  # Indices for eyebrow landmarks\n",
    "            x = landmarks.part(i).x\n",
    "            y = landmarks.part(i).y\n",
    "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "        for i in range(22, 27):  # Indices for right eyebrow landmarks\n",
    "            x = landmarks.part(i).x\n",
    "            y = landmarks.part(i).y\n",
    "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "        # Draw marks on eyes\n",
    "        for i in range(36, 48):  # Indices for eye landmarks\n",
    "            x = landmarks.part(i).x\n",
    "            y = landmarks.part(i).y\n",
    "            cv2.circle(frame, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "        # Calculate the distance between the eyes and eyebrows\n",
    "        eye_eyebrow_distance = (left_eye + right_eye) / 2 - (left_eyebrow + right_eyebrow) / 2\n",
    "        if eye_eyebrow_distance >42:\n",
    "            sunglasses_worn=True\n",
    "        else:\n",
    "            sunglasses_worn=False\n",
    "    # Display the result on the frame\n",
    "    text = \"Sunglasses: \" + str(sunglasses_worn)+\" , Eye brow Distance: \"+str(eye_eyebrow_distance)\n",
    "    cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Face Mask Detection\", frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
